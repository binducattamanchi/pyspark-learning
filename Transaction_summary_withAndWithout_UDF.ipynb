{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5453d2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      "\n",
      "+---+------------+\n",
      "| id|total_amount|\n",
      "+---+------------+\n",
      "|  1|        1000|\n",
      "|  2|        2400|\n",
      "|  3|        1200|\n",
      "|  4|        5000|\n",
      "|  5|        3000|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"transaction\").getOrCreate()\n",
    "\n",
    "cdf=spark.read.csv(\"customer.csv\",header=True)\n",
    "\n",
    "cdf.printSchema()\n",
    "cdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a287ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      "\n",
      "+---+------+------+\n",
      "| id|  type|amount|\n",
      "+---+------+------+\n",
      "|  1|credit|   100|\n",
      "|  1| debit|   200|\n",
      "|  1|credit|    50|\n",
      "|  2|credit|   200|\n",
      "|  2| debit|    50|\n",
      "|  3| debit|   100|\n",
      "|  4|credit|   150|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tdf=spark.read.csv(\"transaction.csv\",header=True)\n",
    "\n",
    "tdf.printSchema()\n",
    "tdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa86fc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----------+\n",
      "| id|  type|amount|new_amount|\n",
      "+---+------+------+----------+\n",
      "|  1|credit|   100|       100|\n",
      "|  1| debit|   200|    -200.0|\n",
      "|  1|credit|    50|        50|\n",
      "|  2|credit|   200|       200|\n",
      "|  2| debit|    50|     -50.0|\n",
      "|  3| debit|   100|    -100.0|\n",
      "|  4|credit|   150|       150|\n",
      "+---+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when,col\n",
    "\n",
    "tdf_neg=tdf.withColumn(\"new_amount\",when( col(\"type\")=='debit', col(\"amount\")*-1).otherwise(col(\"amount\")) )\n",
    "tdf_neg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fcfeb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|sum_amount|\n",
      "+---+----------+\n",
      "|  1|     -50.0|\n",
      "|  2|     150.0|\n",
      "|  3|    -100.0|\n",
      "|  4|     150.0|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "tdf_group=tdf_neg.groupBy(col(\"id\")).agg(sum(\"new_amount\").alias(\"sum_amount\")).orderBy(col(\"id\").asc())\n",
    "                                         \n",
    "tdf_group.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a5a82f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|total_amount|\n",
      "+---+------------+\n",
      "|  1|       950.0|\n",
      "|  2|      2550.0|\n",
      "|  3|      1100.0|\n",
      "|  4|      5150.0|\n",
      "|  5|      3000.0|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce,lit\n",
    "overall_trans=cdf.join(tdf_group,\"id\",\"left\").select(cdf.id,(cdf.total_amount+coalesce(tdf_group.sum_amount,lit(0))).alias(\"total_amount\"))\n",
    "overall_trans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "848cb270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: integer (nullable = true)\n",
      "\n",
      "+---+------+------+\n",
      "| id|  type|amount|\n",
      "+---+------+------+\n",
      "|  1|credit|   100|\n",
      "|  1| debit|   200|\n",
      "|  1|credit|    50|\n",
      "|  2|credit|   200|\n",
      "|  2| debit|    50|\n",
      "|  3| debit|   100|\n",
      "|  4|credit|   150|\n",
      "+---+------+------+\n",
      "\n",
      "+---+------+------+----+\n",
      "| id|  type|amount| new|\n",
      "+---+------+------+----+\n",
      "|  1|credit|   100| 100|\n",
      "|  1| debit|   200|-200|\n",
      "|  1|credit|    50|  50|\n",
      "|  2|credit|   200| 200|\n",
      "|  2| debit|    50| -50|\n",
      "|  3| debit|   100|-100|\n",
      "|  4|credit|   150| 150|\n",
      "+---+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create udf for transaction data\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "tdf_new=tdf.select(col(\"id\"),col(\"type\"),col(\"amount\").cast(\"int\").alias(\"amount\"))\n",
    "tdf_new.printSchema()\n",
    "tdf_new.show()\n",
    "# Define UDF to convert amount based on transaction type\n",
    "x_udf = udf(lambda x, y: -1 * y if x == 'debit' else y, IntegerType())\n",
    "\n",
    "# Apply the UDF\n",
    "df_with_new = tdf_new.withColumn(\"new\", x_udf(col(\"type\"), col(\"amount\")))\n",
    "\n",
    "# Show the result\n",
    "df_with_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d3a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
