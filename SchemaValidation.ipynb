{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a9342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "schema matched\n",
      "schema not matched\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"schema match\").getOrCreate()\n",
    "data1=[(1,'A','A1',100)]\n",
    "schema1=[\"id\",\"name\",\"dept\",\"salary\"]\n",
    "\n",
    "data2=[(1,'A','A1',100)]\n",
    "schema2=[\"id\",\"name\",\"dept\",\"salary\"]\n",
    "data3=[(1,'A',1,100)]\n",
    "schema3=[\"id\",\"name\",\"dept_id\",\"salary\"]\n",
    "\n",
    "df1=spark.createDataFrame(data1,schema1)\n",
    "df2=spark.createDataFrame(data2,schema2)\n",
    "df3=spark.createDataFrame(data3,schema3)\n",
    "\n",
    "df1.printSchema()\n",
    "df2.printSchema()\n",
    "df3.printSchema()\n",
    "\n",
    "if(df1.schema == df2.schema):\n",
    "    print(\"schema matched\")\n",
    "else: print(\"schema not matched\")\n",
    "    \n",
    "\n",
    "if(df1.schema == df3.schema):\n",
    "    print(\"schema matched\")\n",
    "else: print(\"schema not matched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "848e260f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructField('dept', StringType(), True)]\n",
      "[StructField('dept_id', LongType(), True)]\n"
     ]
    }
   ],
   "source": [
    "# get the list of missing columns\n",
    "print(list(set(df1.schema)-set(df3.schema)))\n",
    "print(list(set(df3.schema)-set(df1.schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edc40349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'dept', 'salary', 'id', 'name', 'dept_id', 'salary']\n",
      "{'dept_id', 'salary', 'dept', 'name', 'id'}\n"
     ]
    }
   ],
   "source": [
    "# using columns: get missing columns list\n",
    "\n",
    "df=df1.columns+df3.columns\n",
    "uniqueCol=set(df)\n",
    "print(df)\n",
    "print(uniqueCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c2b9998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string, dept: string, salary: bigint, dept_id: void]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string, dept_id: bigint, salary: bigint, dept: void]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add missing column to df\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "for i in uniqueCol:\n",
    "    if i not in df1.columns:\n",
    "        df1=df1.withColumn(i,lit(None))\n",
    "    if i not in df3.columns:\n",
    "        df3=df3.withColumn(i,lit(None))\n",
    "        \n",
    "\n",
    "display(df1)\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d92bd5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+------+-------+\n",
      "| id|name|dept|salary|dept_id|\n",
      "+---+----+----+------+-------+\n",
      "|  1|   A|  A1|   100|   null|\n",
      "+---+----+----+------+-------+\n",
      "\n",
      "+---+----+-------+------+----+\n",
      "| id|name|dept_id|salary|dept|\n",
      "+---+----+-------+------+----+\n",
      "|  1|   A|      1|   100|null|\n",
      "+---+----+-------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c09866f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
