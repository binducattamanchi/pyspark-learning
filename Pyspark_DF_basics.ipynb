{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f962a6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Seqno: string (nullable = true)\n",
      " |-- Quote: string (nullable = true)\n",
      "\n",
      "+-----+--------------------+\n",
      "|Seqno|               Quote|\n",
      "+-----+--------------------+\n",
      "|    1|Be the change tha...|\n",
      "|    2|Everyone thinks o...|\n",
      "|    3|The purpose of ou...|\n",
      "|    4|             Be Cool|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('DF examples').getOrCreate()\n",
    "columns = [\"Seqno\", \"Quote\"]\n",
    "data = [(\"1\", \"Be the change that you wish to see in the world\"),\n",
    "(\"2\", \"Everyone thinks of changing the world, but no one thinks of changing himself.\"),\n",
    "(\"3\", \"The purpose of our lives is to be happy\"),\n",
    "(\"4\", \"Be Cool\")]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.printSchema()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c56053ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------+\n",
      "|Seqno|Quote                                                                        |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|1    |Be the change that you wish to see in the world                              |\n",
      "|2    |Everyone thinks of changing the world, but no one thinks of changing himself.|\n",
      "|3    |The purpose of our lives is to be happy                                      |\n",
      "|4    |Be Cool                                                                      |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|Seqno|Quote                                                                        |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|1    |Be the change that you wish to see in the world                              |\n",
      "|2    |Everyone thinks of changing the world, but no one thinks of changing himself.|\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----+-------------------------+\n",
      "|Seqno|                    Quote|\n",
      "+-----+-------------------------+\n",
      "|    1|Be the change that you...|\n",
      "|    2|Everyone thinks of cha...|\n",
      "+-----+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display Full Column Contents\n",
    "df.show(truncate = False)\n",
    "# Display 2 rows and full column contents\n",
    "df.show(2, truncate = False)\n",
    "# Display 2 rows and truncate column by length\n",
    "df.show(2, truncate=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cef5cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " Seqno | 1                         \n",
      " Quote | Be the change that you... \n",
      "-RECORD 1--------------------------\n",
      " Seqno | 2                         \n",
      " Quote | Everyone thinks of cha... \n",
      "-RECORD 2--------------------------\n",
      " Seqno | 3                         \n",
      " Quote | The purpose of our liv... \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrames rows & columns vertically\n",
    "df.show(n=3, truncate=25, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b7c12de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Rows count : 4\n",
      "DataFrame Rows Distinct count : 4\n",
      "DataFrame Columns count : 2\n",
      "DataFrame Column count: 2\n"
     ]
    }
   ],
   "source": [
    "# Get row count\n",
    "rows = df.count()\n",
    "print(f\"DataFrame Rows count : {rows}\")\n",
    "\n",
    "# Get distinct row count\n",
    "rows = df.distinct().count()\n",
    "print(f\"DataFrame Rows Distinct count : {rows}\")\n",
    "\n",
    "# Get columns count\n",
    "cols = len(df.columns)\n",
    "print(f\"DataFrame Columns count : {cols}\")\n",
    "\n",
    "\n",
    "# Get Column count Using len(df.dtypes) method\n",
    "col = len(df.dtypes)\n",
    "print(f\"DataFrame Column count: {col}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cad7ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|count(Quote)|\n",
      "+------------+\n",
      "|           4|\n",
      "+------------+\n",
      "\n",
      "+------------+------------+\n",
      "|count(Seqno)|count(Quote)|\n",
      "+------------+------------+\n",
      "|           4|           4|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using functions.count()\n",
    "from pyspark.sql.functions import count\n",
    "df.select(count(df.Quote)).show()\n",
    "df.select(count(df.Seqno), count(df.Quote)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "498beebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|count(Quote)|count(Seqno)|\n",
      "+------------+------------+\n",
      "|           4|           4|\n",
      "+------------+------------+\n",
      "\n",
      "+-----+-----+\n",
      "|Seqno|count|\n",
      "+-----+-----+\n",
      "|    1|    1|\n",
      "|    2|    1|\n",
      "|    3|    1|\n",
      "|    4|    1|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using agg\n",
    "df.agg({'Seqno':'count','Quote':'count'}).show()\n",
    "\n",
    "# Using groupBy().count()\n",
    "df.groupBy(\"Seqno\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88f59b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       4|\n",
      "+--------+\n",
      "\n",
      "+---------------------+\n",
      "|count(DISTINCT Seqno)|\n",
      "+---------------------+\n",
      "|                    4|\n",
      "+---------------------+\n",
      "\n",
      "+-----+--------+\n",
      "|Seqno|count(1)|\n",
      "+-----+--------+\n",
      "|    1|       1|\n",
      "|    2|       1|\n",
      "|    3|       1|\n",
      "|    4|       1|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PySpark SQL Count\n",
    "df.createOrReplaceTempView(\"EMP\")\n",
    "spark.sql(\"SELECT Count(*) FROM EMP\").show()\n",
    "spark.sql(\"SELECT COUNT(distinct Seqno) FROM EMP\").show()\n",
    "spark.sql(\"SELECT Seqno,COUNT(*) FROM EMP GROUP BY Seqno\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c82b5be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+\n",
      "|   Name|     Dept|Salary|\n",
      "+-------+---------+------+\n",
      "|  James|    Sales|  3000|\n",
      "|Michael|    Sales|  4600|\n",
      "| Robert|    Sales|  4100|\n",
      "|  Maria|  Finance|  3000|\n",
      "|  Scott|  Finance|  3300|\n",
      "|    Jen|  Finance|  3900|\n",
      "|   Jeff|Marketing|  3000|\n",
      "|  Kumar|Marketing|  2000|\n",
      "|   Saif|    Sales|  4100|\n",
      "+-------+---------+------+\n",
      "\n",
      "Distinct Count: 9\n"
     ]
    }
   ],
   "source": [
    "# Count distinct values\n",
    "data = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    "  ]\n",
    "columns = [\"Name\",\"Dept\",\"Salary\"]\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.distinct().show()\n",
    "print(\"Distinct Count: \" + str(df.distinct().count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e0086af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|count(DISTINCT Dept, Salary)|\n",
      "+----------------------------+\n",
      "|                           8|\n",
      "+----------------------------+\n",
      "\n",
      "Distinct Count of Department & Salary: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using countDistrinct()\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df2=df.select(countDistinct(\"Dept\",\"Salary\"))\n",
    "df2.show()\n",
    "\n",
    "print(\"Distinct Count of Department & Salary: \"+ str(df2.collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9bba3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------+\n",
      "| Name|     Dept|Salary|\n",
      "+-----+---------+------+\n",
      "| Jeff|Marketing|  3000|\n",
      "|Kumar|Marketing|  2000|\n",
      "+-----+---------+------+\n",
      "\n",
      "+-----+---------+------+\n",
      "| Name|     Dept|Salary|\n",
      "+-----+---------+------+\n",
      "| Jeff|Marketing|  3000|\n",
      "|Kumar|Marketing|  2000|\n",
      "+-----+---------+------+\n",
      "\n",
      "+-----+---------+------+\n",
      "| Name|     Dept|Salary|\n",
      "+-----+---------+------+\n",
      "| Jeff|Marketing|  3000|\n",
      "|Kumar|Marketing|  2000|\n",
      "+-----+---------+------+\n",
      "\n",
      "+-----+---------+------+\n",
      "| Name|     Dept|Salary|\n",
      "+-----+---------+------+\n",
      "| Jeff|Marketing|  3000|\n",
      "|Kumar|Marketing|  2000|\n",
      "+-----+---------+------+\n",
      "\n",
      "+-----+---------+------+\n",
      "| Name|     Dept|Salary|\n",
      "+-----+---------+------+\n",
      "| Jeff|Marketing|  3000|\n",
      "|Kumar|Marketing|  2000|\n",
      "+-----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter not in\n",
    "\n",
    "# PySpark not isin()\n",
    "listValues = [\"Sales\",\"Finance\"]\n",
    "df.filter(~df.Dept.isin(listValues)).show()\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "df.filter(~col(\"Dept\").isin(listValues)).show()\n",
    "\n",
    "# Using NOT IN operator\n",
    "df.filter(\"Dept not in ('Sales','Finance')\" ).show()\n",
    "\n",
    "# Using == operator\n",
    "df.filter(df.Dept.isin(listValues) == False).show()\n",
    "\n",
    "# PySpark SQL NOT IN\n",
    "df.createOrReplaceTempView(\"TAB\")\n",
    "spark.sql(\"SELECT * FROM TAB WHERE \" +\n",
    "    \"Dept NOT IN ('Sales','Finance')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ddae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
